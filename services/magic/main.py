from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Dict, List, Optional
import httpx
import json
from datetime import datetime

app = FastAPI(title="Magic Mode", description="AI that builds ML pipelines from natural language")

class MagicRequest(BaseModel):
    prompt: str
    user_id: str
    auto_deploy: bool = True

class MagicResponse(BaseModel):
    job_id: str
    status: str
    dataset_id: Optional[str] = None
    experiment_id: Optional[str] = None
    model_id: Optional[str] = None
    api_endpoint: Optional[str] = None
    code: Optional[str] = None
    message: str

# Task templates
TEMPLATES = {
    "sentiment": {
        "type": "text_classification",
        "model": "distilbert-base-uncased",
        "dataset_size": 10000,
        "epochs": 3
    },
    "classification": {
        "type": "classification",
        "model": "resnet50",
        "dataset_size": 5000,
        "epochs": 10
    },
    "generation": {
        "type": "text_generation",
        "model": "gpt2",
        "dataset_size": 5000,
        "epochs": 5
    }
}

def parse_intent(prompt: str) -> Dict:
    """Parse user intent from natural language"""
    prompt_lower = prompt.lower()
    
    # Detect task type
    if "sentiment" in prompt_lower:
        task_type = "sentiment"
        task_name = "Sentiment Analysis"
    elif "classify" in prompt_lower or "classification" in prompt_lower:
        task_type = "classification"
        task_name = "Classification"
    elif "generate" in prompt_lower or "generation" in prompt_lower:
        task_type = "generation"
        task_name = "Text Generation"
    else:
        task_type = "classification"
        task_name = "Classification"
    
    # Detect data source
    if "tweet" in prompt_lower or "twitter" in prompt_lower:
        data_source = "twitter"
    elif "image" in prompt_lower:
        data_source = "images"
    elif "text" in prompt_lower:
        data_source = "text"
    else:
        data_source = "synthetic"
    
    return {
        "task_type": task_type,
        "task_name": task_name,
        "data_source": data_source,
        "template": TEMPLATES.get(task_type, TEMPLATES["classification"])
    }

def generate_code(intent: Dict, dataset_id: str, experiment_id: str) -> str:
    """Generate Python code for the ML pipeline"""
    code = f'''
# Auto-generated by AI-DOS Magic Mode
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments
from datasets import load_dataset

# Load dataset from AI-DOS DataForge
dataset_id = "{dataset_id}"
experiment_id = "{experiment_id}"

# Load model
model_name = "{intent["template"]["model"]}"
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Training configuration
training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs={intent["template"]["epochs"]},
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_steps=10,
)

# Train model
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
)

trainer.train()

# Save model
model.save_pretrained("./model")
tokenizer.save_pretrained("./model")

print("✅ Training complete!")
print(f"✅ Model saved to ./model")
print(f"✅ Experiment ID: {{experiment_id}}")
'''
    return code

@app.post("/magic/create", response_model=MagicResponse)
async def create_magic(request: MagicRequest):
    """
    Magic Mode: Create complete ML pipeline from natural language
    
    Example: "Build a sentiment analyzer for tweets"
    
    This will:
    1. Parse intent
    2. Create dataset
    3. Generate code
    4. Train model
    5. Deploy to production
    6. Return API endpoint
    """
    try:
        job_id = f"magic_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Step 1: Parse intent
        intent = parse_intent(request.prompt)
        
        # Step 2: Create dataset in DataForge
        async with httpx.AsyncClient() as client:
            dataset_response = await client.post(
                "http://dataforge:8000/datasets",
                json={
                    "name": f"{intent['task_name']} Dataset",
                    "description": f"Auto-generated for: {request.prompt}",
                    "owner_id": request.user_id,
                    "data_type": intent["data_source"]
                }
            )
            dataset_data = dataset_response.json()
            dataset_id = dataset_data["id"]
        
        # Step 3: Create experiment in ModelHub
        async with httpx.AsyncClient() as client:
            experiment_response = await client.post(
                "http://modelhub:8000/experiments",
                json={
                    "name": f"{intent['task_name']} Experiment",
                    "description": f"Auto-generated for: {request.prompt}",
                    "project_id": "magic-mode",
                    "user_id": request.user_id,
                    "tags": ["magic-mode", intent["task_type"]]
                }
            )
            experiment_data = experiment_response.json()
            experiment_id = experiment_data["id"]
        
        # Step 4: Generate code
        code = generate_code(intent, dataset_id, experiment_id)
        
        # Step 5: Simulate training (in real version, this would submit to TrainOS)
        model_id = f"model_{job_id}"
        
        # Step 6: Simulate deployment (in real version, this would use DeployEngine)
        api_endpoint = f"https://api.ai-dos.io/{model_id}/predict" if request.auto_deploy else None
        
        return MagicResponse(
            job_id=job_id,
            status="completed",
            dataset_id=dataset_id,
            experiment_id=experiment_id,
            model_id=model_id,
            api_endpoint=api_endpoint,
            code=code,
            message=f"✅ Created {intent['task_name']} pipeline! Dataset: {dataset_id}, Experiment: {experiment_id}"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/magic/status/{job_id}")
async def get_status(job_id: str):
    """Get status of a magic job"""
    return {
        "job_id": job_id,
        "status": "completed",
        "progress": 100,
        "message": "Pipeline created successfully"
    }

@app.get("/health")
async def health():
    return {"status": "healthy", "service": "magic"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8003)
